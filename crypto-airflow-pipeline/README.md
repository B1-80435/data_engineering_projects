# ğŸª‚ Crypto Price Data Pipeline using Apache Airflow

An end-to-end data engineering project that automates the extraction, validation, storage, and scheduling of real-time cryptocurrency prices using **Apache Airflow**, **Python**, **Docker**, and **PostgreSQL**.

---

## ğŸš€ Project Overview

This project builds a **daily ETL pipeline** using Apache Airflow to:

- Fetch real-time crypto prices (Bitcoin & Ethereum) via the [CoinGecko API](https://www.coingecko.com/en/api)
- Perform data quality checks
- Store data in:
  - A local **CSV file**
  - A **PostgreSQL** database
- (Optional) Plot crypto trends using `matplotlib`
- Schedule all tasks via an Airflow **DAG**, with retries and failure email alerts

---

## ğŸ“‚ Folder Structure

```

crypto-airflow-pipeline/
â”‚
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ crypto\_dag.py             â† Airflow DAG definition
â”‚
â”œâ”€â”€ crypto\_pipeline/
â”‚   â”œâ”€â”€ fetch\_crypto\_data.py      â† API call and data fetching
â”‚   â”œâ”€â”€ save\_data.py              â† Save to CSV & PostgreSQL
â”‚
â”œâ”€â”€ requirements.txt              â† Project dependencies
â”œâ”€â”€ README.md                     â† Project documentation
â””â”€â”€ .gitignore                    â† Python & Airflow ignores

````

---

## ğŸ”§ Technologies Used

| Tool             | Purpose                          |
|------------------|----------------------------------|
| **Python**       | Data fetching, validation, I/O   |
| **Apache Airflow** | Workflow orchestration         |
| **Docker**       | Containerized Airflow environment |
| **PostgreSQL**   | Structured data storage          |
| **CoinGecko API**| Real-time crypto price source    |
| **Pandas**       | Data manipulation                |
| **Matplotlib**   | Optional visualizations          |

---

## ğŸ” Workflow / DAG Description

```text
fetch_and_store_crypto_data
    |
    â”œâ”€â”€ get_crypto_prices()       â†’ fetch BTC/ETH prices from CoinGecko
    â”œâ”€â”€ check_data_quality()      â†’ null and negative value validation
    â”œâ”€â”€ save_to_csv()             â†’ backup snapshot locally
    â””â”€â”€ save_to_postgres()        â†’ insert data into PostgreSQL
````

Each task has:

* Retries
* Email alerts on failure
* Scheduled execution (@daily)

---

## ğŸ“Š Sample Output (in PostgreSQL)

| name     | price\_usd | date                       |
| -------- | ---------- | -------------------------- |
| bitcoin  | 99586.00   | 2025-05-08 15:21:13.951527 |
| ethereum | 1934.93    | 2025-05-08 15:21:13.951527 |

---

## ğŸ§ª How to Run the Project (Local Setup)

> Docker is required (Airflow runs in containers)

```bash
# Clone the repo
git clone https://github.com/<your-username>/crypto-airflow-pipeline.git
cd crypto-airflow-pipeline

# Run Docker containers
docker-compose up -d

# Access Airflow UI
http://localhost:8080
```

* Default Airflow login: `admin` / `admin`
* Trigger the DAG `crypto_price_pipeline` manually or wait for scheduled run

---

## ğŸ“¬ Future Improvements

* Add Streamlit dashboard to visualize crypto trends
* Extend DAG to track more coins
* Integrate with Kafka for real-time streaming (advanced)

---

## ğŸ™Œ Credits

Built with love by **Tanzeel Mansuri**
[LinkedIn](https://linkedin.com/in/tanzeel-mansuri) â€¢ [GitHub](https://github.com/B1-80435/data_engineering_projects)

---

## ğŸ·ï¸ Tags

`#DataEngineering` `#ApacheAirflow` `#Python` `#Docker` `#PostgreSQL` `#CryptoPipeline` `#ETL`

```

